{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bp import data_gather_from_files,run_strategy_optimised,run_strategy_eval\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "num_cores = multiprocessing.cpu_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_check(params,n):\n",
    "    if len(params) != n:\n",
    "        raise IndexError('The number of parameters is not correct')\n",
    "\n",
    "def generate_date_ranges_for_walk_forward(start_month_year, end_month_year, day=15, n_months = 1):\n",
    "    # Initialize an empty list to store the date ranges\n",
    "    date_ranges = []\n",
    "    if day not in range(1, 29):\n",
    "        raise ValueError('Day must be between 1 and 28')\n",
    "    # Convert the input strings to datetime objects, using the given day\n",
    "    start_date = datetime.strptime(f\"{day} {start_month_year}\", '%d %b %Y')\n",
    "    end_date = datetime.strptime(f\"{day} {end_month_year}\", '%d %b %Y')\n",
    "    \n",
    "    # Generate the date ranges\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        next_date = current_date + relativedelta(months=n_months)\n",
    "        date_range = [current_date.strftime('%d %b %Y'), (next_date - relativedelta(days=1)).strftime('%d %b %Y')]\n",
    "        date_ranges.append(date_range)\n",
    "        current_date = next_date\n",
    "    \n",
    "    return date_ranges[:-1]\n",
    "\n",
    "def get_previous_n_months(end_date_str, n_months):\n",
    "    # Convert the input string to a datetime object\n",
    "    end_date = datetime.strptime(end_date_str, '%d %b %Y')\n",
    "    \n",
    "    # Calculate the start date\n",
    "    start_date = end_date - relativedelta(months=n_months)\n",
    "    \n",
    "    # Create the date range\n",
    "    date_range = [start_date.strftime('%d %b %Y'), (end_date - relativedelta(days=1)).strftime('%d %b %Y')]\n",
    "    \n",
    "    return date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_analysis(evaluation_start, evaluation_end, evaluation_day,parameters,optimization_function = None, optimizer_params =[],  lookback_in_months = 6,evaluation_period = 3):\n",
    "    generated_date_ranges = generate_date_ranges_for_walk_forward(evaluation_start, evaluation_end,evaluation_day,n_months = evaluation_period)\n",
    "    df = {}\n",
    "    for dates in generated_date_ranges:\n",
    "        train_period = get_previous_n_months(dates[0], lookback_in_months)\n",
    "        train_data = data_gather_from_files(train_period[0],train_period[1])['EURUSD.mid']\n",
    "        print('Data gathered for training period: ',train_period[0],train_period[1])\n",
    "        test_data = data_gather_from_files(dates[0],dates[1])['EURUSD.mid']\n",
    "        print('Data gathered for testing period: ',dates[0],dates[1])\n",
    "        max_loss, U_PNL, max_position, R_PNL,profit,optimal_params = optimization_function(train_data,test_data,parameters,optimizer_params)\n",
    "        print('Optimal parameters are: ',optimal_params)\n",
    "        #add optimization phrase evaluation G,n,d\n",
    "        a, b, c, d, e = run_strategy_optimised(train_data, optimal_params[0],optimal_params[1],optimal_params[2])\n",
    "        print('Optimization phrase; Max loss, U_PNL, max_position, R_PNL,profit are: ',a, b, c, d, e)\n",
    "        ##\n",
    "        print('Training phrase; Max loss, U_PNL, max_position, R_PNL,profit are: ',max_loss, U_PNL, max_position, R_PNL,profit)\n",
    "        df[dates[0] +'-'+ dates[1]] = [max_loss, U_PNL, max_position, R_PNL,profit]\n",
    "    df = pd.DataFrame(df).T\n",
    "    df.columns = ['max_loss', 'min_U_PNL', 'max_position', 'R_PNL','profit']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_map(evaluate_function, items, num_processes):\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = pool.map(evaluate_function, items)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from deap import base, creator, tools\n",
    "\n",
    "def objective(individual, train_data, grid_params, position_params):\n",
    "    G, n, d = individual[0]*grid_params[2], individual[1]*position_params[2], individual[2]\n",
    "    max_loss, U_PNL, max_position, R_PNL, profit = run_strategy_optimised(train_data, G, n, d)\n",
    "    \n",
    "    constraints = [\n",
    "        max_position > 10e6,\n",
    "        U_PNL < -150e3,\n",
    "        max_loss < -500e3\n",
    "        # scaling_factor * n * d > 10e6  # Uncomment if you have scaling_factor in your genes\n",
    "    ]\n",
    "\n",
    "    if any(constraints):\n",
    "        return float('-inf'),  # Return large negative value when constraints are not satisfied\n",
    "    return profit,\n",
    "\n",
    "def deap_optimiser_g_n_d(train_data, test_data, parameters, optimization_params):\n",
    "    ngen = optimization_params[0]  # number of generations\n",
    "    npop = optimization_params[1]  # number of population\n",
    "    error_check(parameters,3)\n",
    "    \n",
    "    grid_params = parameters[0]\n",
    "    position_params = parameters[1]\n",
    "    depth_params = parameters[2]\n",
    "\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,)) #maximizing\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # Define the genes for our individual\n",
    "    toolbox.register(\"G_gene\", random.randint, grid_params[0]//grid_params[2], grid_params[1]//grid_params[2])\n",
    "    toolbox.register(\"n_gene\", random.randint, position_params[0]//position_params[2], position_params[1]//position_params[2])\n",
    "    toolbox.register(\"d_gene\", random.randint, depth_params[0], depth_params[1])\n",
    "\n",
    "    # Create an individual with the genes\n",
    "    toolbox.register(\"individual\", tools.initCycle, creator.Individual, (toolbox.G_gene, toolbox.n_gene, toolbox.d_gene), n=1)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutUniformInt, low=[grid_params[0]//grid_params[2], position_params[0]//position_params[2], depth_params[0]], \n",
    "                     up=[grid_params[1]//grid_params[2], position_params[1]//position_params[2], depth_params[1]], indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    toolbox.register(\"evaluate\", objective, train_data=train_data, grid_params=grid_params, position_params=position_params)\n",
    "\n",
    "    population = toolbox.population(n=npop)\n",
    "    CXPB, MUTPB = 0.5, 0.2\n",
    "\n",
    "    # Evaluate the entire population\n",
    "    #num_cores = 4  # Or however many cores you want to use or have available\n",
    "    fitnesses = parallel_map(toolbox.evaluate, population, num_cores)\n",
    "\n",
    "    #fitnesses = list(map(toolbox.evaluate, population))\n",
    "    for ind, fit in zip(population, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    #initiate early stopping\n",
    "    stagnant_generations = 0  # Counter for generations without improvement\n",
    "    MAX_STAGNANT_GEN = 20  # Early stopping criterion: stop if no improvement over x generations\n",
    "    best_fitness_so_far = float('-inf')  # since we're maximizing\n",
    "    ##\n",
    "    for gen in range(ngen):\n",
    "        offspring = toolbox.select(population, len(population))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "        \n",
    "        # Crossover\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < CXPB:\n",
    "                toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "        \n",
    "        # Mutation\n",
    "        for mutant in offspring:\n",
    "            if random.random() < MUTPB:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "\n",
    "        #fitnesses = list(map(toolbox.evaluate, offspring))\n",
    "        fitnesses = parallel_map(toolbox.evaluate, offspring, num_cores)\n",
    "\n",
    "        for ind, fit in zip(offspring, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        #early stopping\n",
    "        current_best_fitness = max(ind.fitness.values[0] for ind in population)\n",
    "\n",
    "        if current_best_fitness > best_fitness_so_far:\n",
    "            best_fitness_so_far = current_best_fitness\n",
    "            stagnant_generations = 0  # Reset counter\n",
    "        else:\n",
    "            stagnant_generations += 1\n",
    "\n",
    "        if stagnant_generations >= MAX_STAGNANT_GEN:\n",
    "            print(f\"Early stopping on generation {gen} due to no improvement.\")\n",
    "            break\n",
    "        ##\n",
    "        population[:] = offspring\n",
    "\n",
    "    best_ind = tools.selBest(population, 1)[0]\n",
    "    optimal_g = best_ind[0]*grid_params[2]\n",
    "    optimal_n = best_ind[1]*position_params[2]\n",
    "    optimal_d = best_ind[2]\n",
    "    print(\"optimisation completed\")\n",
    "    max_loss, U_PNL, max_position, R_PNL,profit = run_strategy_optimised(test_data, optimal_g,optimal_n,optimal_d)\n",
    "    return max_loss, U_PNL, max_position, R_PNL,profit,[optimal_g,optimal_n,optimal_d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of grid params:- 18.0\n",
      "number of lot params:- 19.0\n",
      "number of depth params:- 9.0\n",
      "total_number_of_combinations:- 3078.0\n",
      "Data gathered for training period:  01 Dec 2020 31 Dec 2020\n",
      "Data gathered for testing period:  01 Jan 2021 31 Jan 2021\n"
     ]
    }
   ],
   "source": [
    "grid_params = [0.001,0.01,0.0005]\n",
    "lot_params = [100000,2000000,100000]\n",
    "depth_params = [3,12,1]\n",
    "\n",
    "n_grid_params = ((grid_params[1]-grid_params[0])/grid_params[2])\n",
    "n_lot_params = ((lot_params[1]-lot_params[0])/lot_params[2])\n",
    "n_depth_params = ((depth_params[1]-depth_params[0])/depth_params[2])\n",
    "\n",
    "print('number of grid params:-',(n_grid_params))\n",
    "print('number of lot params:-',(n_lot_params))\n",
    "print('number of depth params:-',(n_depth_params))\n",
    "print('total_number_of_combinations:-',(n_grid_params*n_lot_params*n_depth_params))\n",
    "\n",
    "# Adjust these parameter according to number of iterations\n",
    "n_trials = 50 #NGEN 50-100 \n",
    "npop = 300 # around 10% of search space\n",
    "optimizer_param = [n_trials, npop]\n",
    "\n",
    "parameters = [grid_params,lot_params,depth_params]\n",
    "results = walk_forward_analysis('jan 2021','jan 2022',1,parameters,optimization_function=deap_optimiser_g_n_d,optimizer_params=[n_trials, npop],lookback_in_months=1,evaluation_period=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
